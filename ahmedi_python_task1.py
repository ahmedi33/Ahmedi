# -*- coding: utf-8 -*-
"""Ahmedi_python_task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17KAboeyjHi5ACvVJqNssumonKlOqmAMP
"""

import pandas as pd

def generate_car_matrix(df)->pd.DataFrame:
    """
    Creates a DataFrame  for id combinations.

    Args:
        df (pandas.DataFrame)

    Returns:
        pandas.DataFrame: Matrix generated with 'car' values,
                          where 'id_1' and 'id_2' are used as indices and columns respectively.
    """
    # Write your logic here

    return df
 Create an empty dictionary to store the values for the matrix
    matrix_data = {}

    # Iterate through the rows of the DataFrame
    for index, row in df.iterrows():
        # Extract values from the row
        id_1 = row['id_1']
        id_2 = row['id_2']
        car_value = row['car']

        # Check if the index for id_1 exists in the dictionary
        if id_1 not in matrix_data:
            matrix_data[id_1] = {}

        # Assign the car value to the corresponding id_2 in the dictionary
        matrix_data[id_1][id_2] = car_value

    # Create a DataFrame from the dictionary
    car_matrix = pd.DataFrame(matrix_data)

    return car_matrix

# Example usage:
# Assuming you have a DataFrame named 'your_dataframe'
# car_matrix_result = generate_car_matrix(your_dataframe)

def get_type_count(df)->dict:
    """
    Categorizes 'car' values into types and returns a dictionary of counts.

    Args:
        df (pandas.DataFrame)

    Returns:
        dict: A dictionary with car types as keys and their counts as values.
    """
    # Write your logic here
     # Group by the 'car' column and count occurrences of each type
    car_counts = df['car'].value_counts().to_dict()

    return car_counts

# Example usage:
# Assuming you have a DataFrame named 'your_dataframe'
# type_count_result = get_type_count(your_dataframe)

    return dict()

def get_bus_indexes(df)->list:
    """
    Returns the indexes where the 'bus' values are greater than twice the mean.

    Args:
        df (pandas.DataFrame)

    Returns:
        list: List of indexes where 'bus' values exceed twice the mean.
    """
    # Write your logic here
     # Calculate the mean of 'bus' values
    bus_mean = df['bus'].mean()

    # Find the indexes where 'bus' values exceed twice the mean
    bus_indexes = df[df['bus'] > 2 * bus_mean].index.tolist()

    return bus_indexes

# Example usage:
# Assuming you have a DataFrame named 'your_dataframe'
# bus_indexes_result = get_bus_indexes(your_dataframe)

    return list()

def filter_routes(df)->list:
    """
    Filters and returns routes with average 'truck' values greater than 7.

    Args:
        df (pandas.DataFrame)

    Returns:
        list: List of route names with average 'truck' values greater than 7.
    """
    # Write your logic here
    # Calculate the mean 'truck' values for each route
    route_avg_truck = df.groupby('route')['truck'].mean()

    # Filter routes where average 'truck' values are greater than 7
    selected_routes = route_avg_truck[route_avg_truck > 7].index.tolist()

    return selected_routes

# Example usage:
# Assuming you have a DataFrame named 'your_dataframe'
# selected_routes_result = filter_routes(your_dataframe)

    return list()

def multiply_matrix(matrix)->pd.DataFrame:
    """
    Multiplies matrix values with custom conditions.

    Args:
        matrix (pandas.DataFrame)

    Returns:
        pandas.DataFrame: Modified matrix with values multiplied based on custom conditions.
    """
    # Write your logic here
    # Write your custom multiplication logic here
    # For example, let's multiply values greater than 5 by 2

    # Use applymap to apply the custom condition to each element of the matrix
    modified_matrix = matrix.applymap(lambda x: x * 2 if x > 5 else x)

    return modified_matrix

# Example usage:
# Assuming you have a DataFrame named 'your_matrix'
# modified_matrix_result = multiply_matrix(your_matrix)

    return matrix

def time_check(df)->pd.Series:
    """
    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period

    Args:
        df (pandas.DataFrame)

    Returns:
        pd.Series: return a boolean series
    """
    # Write your logic here
    # Assuming 'timestamp' is the column containing timestamps in your DataFrame
    df['timestamp'] = pd.to_datetime(df['timestamp'])

    # Calculate time differences for each unique (`id`, `id_2`) pair
    time_diff = df.groupby(['id', 'id_2'])['timestamp'].agg(lambda x: (x.max() - x.min()).total_seconds())

    # Check if the time differences cover a full 24-hour and 7 days period
    completeness_check = (time_diff >= 24 * 60 * 60) & (time_diff >= 7 * 24 * 60 * 60)

    return completeness_check

# Example usage:
# completeness_series = time_check(your_dataframe)

    return pd.Series()